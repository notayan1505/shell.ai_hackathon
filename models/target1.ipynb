{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a939af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for target 1 / 10\n",
      "[0]\tvalidation_0-mae:0.77284\n",
      "[50]\tvalidation_0-mae:0.33231\n",
      "[100]\tvalidation_0-mae:0.23385\n",
      "[150]\tvalidation_0-mae:0.19465\n",
      "[200]\tvalidation_0-mae:0.17358\n",
      "[250]\tvalidation_0-mae:0.15999\n",
      "[300]\tvalidation_0-mae:0.15103\n",
      "[350]\tvalidation_0-mae:0.14422\n",
      "[400]\tvalidation_0-mae:0.14003\n",
      "[450]\tvalidation_0-mae:0.13743\n",
      "[500]\tvalidation_0-mae:0.13550\n",
      "[550]\tvalidation_0-mae:0.13403\n",
      "[600]\tvalidation_0-mae:0.13317\n",
      "[650]\tvalidation_0-mae:0.13250\n",
      "[700]\tvalidation_0-mae:0.13193\n",
      "[750]\tvalidation_0-mae:0.13147\n",
      "[800]\tvalidation_0-mae:0.13098\n",
      "[850]\tvalidation_0-mae:0.13053\n",
      "[870]\tvalidation_0-mae:0.13052\n",
      "\n",
      "Train MAPE for target 1: 0.2759\n",
      "Validation MAPE for target 1: 0.6180\n",
      "\n",
      "Top 20 most important features by total gain:\n",
      "                                        feature  importance\n",
      "0   Component2_fraction_div_Component5_fraction   21.788336\n",
      "1                           Component5_fraction   11.120496\n",
      "2   Component1_fraction_div_Component5_fraction    7.787182\n",
      "3     Component4_fraction_x_Component5_fraction    6.442931\n",
      "4     Component1_fraction_x_Component2_fraction    5.011199\n",
      "5                 Component3_Property1_weighted    5.009842\n",
      "6   Component2_fraction_div_Component4_fraction    3.697541\n",
      "7                 Component1_Property1_weighted    3.332415\n",
      "8                 Component2_Property1_weighted    3.251115\n",
      "9                 Component5_Property1_weighted    2.308498\n",
      "10                         Component5_Property1    2.187638\n",
      "11                Component4_Property1_weighted    2.182884\n",
      "12                         Component4_Property1    2.180722\n",
      "13  Component2_fraction_div_Component3_fraction    1.895180\n",
      "14                          Component2_fraction    1.815885\n",
      "15                          Component3_fraction    1.535682\n",
      "16    Component3_fraction_x_Component5_fraction    1.341883\n",
      "17                         Component1_Property1    1.153846\n",
      "18                         Component2_Property1    0.748281\n",
      "19    Component3_fraction_x_Component4_fraction    0.670243\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Feature engineering function from before (no PCA, with interactions and weighted props)\n",
    "def engineer_features_no_pca(df):\n",
    "    df = df.copy()\n",
    "    new_cols = {}\n",
    "\n",
    "    # Weighted component-property features\n",
    "    for comp in range(1, 6):\n",
    "        for prop in range(1, 11):\n",
    "            prop_col = f'Component{comp}_Property{prop}'\n",
    "            frac_col = f'Component{comp}_fraction'\n",
    "            new_cols[f'{prop_col}_weighted'] = df[prop_col] * df[frac_col]\n",
    "\n",
    "    # Interaction features between fractions\n",
    "    for i in range(1, 6):\n",
    "        frac_i = f'Component{i}_fraction'\n",
    "        for j in range(i + 1, 6):\n",
    "            frac_j = f'Component{j}_fraction'\n",
    "            new_cols[f'{frac_i}_x_{frac_j}'] = df[frac_i] * df[frac_j]\n",
    "            new_cols[f'{frac_i}_div_{frac_j}'] = df[frac_i] / (df[frac_j] + 1e-8)\n",
    "\n",
    "    # Ratios to total fraction\n",
    "    total_fraction = sum(df[f'Component{i}_fraction'] for i in range(1, 6))\n",
    "    new_cols['Total_fraction'] = total_fraction\n",
    "    for i in range(1, 6):\n",
    "        frac_col = f'Component{i}_fraction'\n",
    "        new_cols[f'{frac_col}_to_total'] = df[frac_col] / (total_fraction + 1e-8)\n",
    "\n",
    "    # Aggregate stats for component properties\n",
    "    for comp in range(1, 6):\n",
    "        props = [f'Component{comp}_Property{p}' for p in range(1, 11)]\n",
    "        new_cols[f'Component{comp}_prop_mean'] = df[props].mean(axis=1)\n",
    "        new_cols[f'Component{comp}_prop_std'] = df[props].std(axis=1)\n",
    "        new_cols[f'Component{comp}_prop_min'] = df[props].min(axis=1)\n",
    "        new_cols[f'Component{comp}_prop_max'] = df[props].max(axis=1)\n",
    "        new_cols[f'Component{comp}_prop_range'] = new_cols[f'Component{comp}_prop_max'] - new_cols[f'Component{comp}_prop_min']\n",
    "\n",
    "    # Polynomial features for component fractions (squares)\n",
    "    for i in range(1, 6):\n",
    "        frac_col = f'Component{i}_fraction'\n",
    "        new_cols[f'{frac_col}_squared'] = df[frac_col] ** 2\n",
    "\n",
    "    # Cross product polynomial features\n",
    "    for i in range(1, 6):\n",
    "        frac_i = f'Component{i}_fraction'\n",
    "        for j in range(i + 1, 6):\n",
    "            frac_j = f'Component{j}_fraction'\n",
    "            new_cols[f'{frac_i}_x_{frac_j}'] = df[frac_i] * df[frac_j]\n",
    "\n",
    "    # Combine original df with new columns\n",
    "    new_features_df = pd.DataFrame(new_cols, index=df.index)\n",
    "    df = pd.concat([df, new_features_df], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# 1. Load data\n",
    "X = pd.read_csv('/Users/xDAyN/Desktop/cs project/Project Shell.ai Hackathon/dataset/X_train.csv')\n",
    "y = pd.read_csv('/Users/xDAyN/Desktop/cs project/Project Shell.ai Hackathon/dataset/y_train.csv')\n",
    "X_test = pd.read_csv('/Users/xDAyN/Desktop/cs project/Project Shell.ai Hackathon/dataset/X_test.csv')\n",
    "\n",
    "# 2. Feature engineering\n",
    "X_fe = engineer_features_no_pca(X)\n",
    "X_test_fe = engineer_features_no_pca(X_test)\n",
    "\n",
    "# 3. Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_fe, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Train model for target 1 only (index 0)\n",
    "target_index = 0\n",
    "print(f\"Training model for target {target_index + 1} / {y.shape[1]}\")\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    max_depth=3,\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    reg_alpha=0.95,\n",
    "    reg_lambda=5.1,\n",
    "    eval_metric='mae',\n",
    "    random_state=42,\n",
    "    verbosity=1,\n",
    "    early_stopping_rounds = 25\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train.iloc[:, target_index],\n",
    "    eval_set=[(X_val, y_val.iloc[:, target_index])],\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "# 5. Predict on train and validation sets\n",
    "train_preds = model.predict(X_train)\n",
    "val_preds = model.predict(X_val)\n",
    "\n",
    "# ... [your original code here unchanged] ...\n",
    "\n",
    "# 6. Evaluate\n",
    "train_mape = mean_absolute_percentage_error(y_train.iloc[:, target_index], train_preds)\n",
    "val_mape = mean_absolute_percentage_error(y_val.iloc[:, target_index], val_preds)\n",
    "\n",
    "print(f\"\\nTrain MAPE for target {target_index + 1}: {train_mape:.4f}\")\n",
    "print(f\"Validation MAPE for target {target_index + 1}: {val_mape:.4f}\")\n",
    "\n",
    "# --- NEW: Show feature importance by total gain ---\n",
    "importance_dict = model.get_booster().get_score(importance_type='gain')\n",
    "importance_df = (\n",
    "    pd.DataFrame({\n",
    "        'feature': list(importance_dict.keys()),\n",
    "        'importance': list(importance_dict.values())\n",
    "    })\n",
    "    .sort_values(by='importance', ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 20 most important features by total gain:\")\n",
    "print(importance_df.head(20))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
